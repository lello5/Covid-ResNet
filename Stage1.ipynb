{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDpeCRsiF7kV"
      },
      "source": [
        "Stage 1 training on 128*128 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDBEKKEnEq9v",
        "outputId": "ffdcd1b6-61aa-417f-f334-daff7d200ca8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAZ07Rs0pg8u"
      },
      "source": [
        "%cd drive/MyDrive\n",
        "%cd Project/COVID-19-master\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPZUIptJ5CQt"
      },
      "source": [
        "# # #importing \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YVqCCFcuBg3"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8yC4E1i_5oD"
      },
      "source": [
        "Load npy files of each sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igRoYtFWOTW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d00d5205-b754-4452-d515-7ebf78733457"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "xtrain_224 = np.load('data/x_train.npy')\n",
        "print(\"RUN HOGAYA\")\n",
        "ytrain = np.load('data/y_train.npy')\n",
        "    \n",
        "xtest = np.load('data/x_test.npy')\n",
        "ytest = np.load('data/y_test.npy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RUN HOGAYA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3nkT6VvOgpU"
      },
      "source": [
        "Main code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvcZRAUKsF2O"
      },
      "source": [
        "def confusion_matrix_info(y_true, y_pred, labels=['normal', 'pneumonia',  'COVID-19'],\n",
        "                          title='confusion matrix'):\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "    from sklearn.metrics import confusion_matrix, f1_score\n",
        "    import matplotlib.pyplot as plt\n",
        "    C2 = confusion_matrix(y_true, y_pred)\n",
        "    C = pd.DataFrame(C2, columns=labels, index=labels)\n",
        "    m, _ = C2.shape\n",
        "    for i in range(m):\n",
        "        precision = C2[i, i] / sum(C2[:, i])\n",
        "        recall = C2[i, i] / sum(C2[i, :])\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "        print('In class {}:\\t total samples: {}\\t true predict samples: {}\\t'\n",
        "              'acc={:.4f},\\trecall={:.4f},\\tf1-score={:.4f}'.format(\n",
        "            labels[i], sum(C2[i, :]), C2[i, i], precision, recall, f1))\n",
        "    print('-' * 100, '\\n', 'average f1={:.4f}'.format(f1_score(y_true, y_pred, average='micro')))\n",
        " \n",
        "    f, ax = plt.subplots()\n",
        "    sns.heatmap(C, annot=True, ax=ax, cmap=plt.cm.binary)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('predict')\n",
        "    ax.set_ylabel('true')\n",
        "    plt.savefig(title+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFQAuF4LySSs"
      },
      "source": [
        "\n",
        "resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "NUM_CLASSES = 3\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Z7sEgdd2FW"
      },
      "source": [
        "#resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "NUM_CLASSES = 3\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "\n",
        "def first_keras_model():\n",
        "    model1 = Sequential()\n",
        "\n",
        "    # 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "    # NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
        "    model1.add(ResNet50(include_top = False,input_shape=(128,128,3), pooling = 'avg', weights = resnet_weights_path))\n",
        "    model1.add(BatchNormalization())\n",
        "\n",
        "    # 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
        "    model1.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
        "\n",
        "    # Say not to train first layer (ResNet) model as it is already trained\n",
        "    \n",
        "    return model1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGl2kD9Oi5Z"
      },
      "source": [
        "def train(xtrain128, y):\n",
        "    y = tf.keras.utils.to_categorical(y, 3)\n",
        "    \n",
        "    #TRAINING ON 128*128 WITH FREEZED RESNET LAYER\n",
        "    model = first_keras_model()\n",
        "    model=model\n",
        "    model.layers[0].trainable = False\n",
        "    print(model.summary())\n",
        "    opt=tf.keras.optimizers.Adam(lr=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    hist = model.fit(xtrain128, y, batch_size=32,  epochs=3, verbose=1)\n",
        "\n",
        "\n",
        "    #FINE TUNING ON 128*128 WITH UNFREEZED RESNET LAYER\n",
        "    model.layers[0].trainable = True\n",
        "    print(model.summary())\n",
        "    opt=tf.keras.optimizers.Adam(lr=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    hist = model.fit(xtrain128, y, batch_size=32,  epochs=5, verbose=1)\n",
        "    model.save('model1.h5')\n",
        "    y_pred = model2.predict(xtrain128)\n",
        "    confusion_matrix_info(np.argmax(y, axis=1), np.argmax(y_pred, axis=1),title='confusion_matrix_train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMcHH1qUsSZN"
      },
      "source": [
        "def test(xt, yt):\n",
        "    model = tf.keras.models.load_model('model1.h5')\n",
        "    xt = np.load('data/x_test.npy')\n",
        "    yt = np.load('data/y_test.npy')\n",
        "    y_pred = model.predict(xt)\n",
        "    confusion_matrix_info(yt, np.argmax(y_pred, axis=1),title='confusion_matrix_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd0EDNOlOnBg"
      },
      "source": [
        "train(xtrain_128,xtrain_224,xtrain_229, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp2L5HpyqV8c"
      },
      "source": [
        "test(xtest, ytest)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}